{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando POS-Taggers para sentenças em Português com NLTK\n",
    "\n",
    "Neste notebook vamos treinar POS-taggers em cima do conjunto de dados [Mac-Morpho](http://nilc.icmc.usp.br/macmorpho/), que é composto de sentenças com as POS taggeadas. Para maiores informações das classificações do corpus, consulte o [Manual](http://nilc.icmc.usp.br/macmorpho/macmorpho-manual.pdf).\n",
    "\n",
    "Vamos fazer o treinamento de vários POS-taggers utilizando as ferramentas do próprio NLTK. \n",
    "Para treinamento e uso dos modelos, certifique-se que tenha baixado os seguintes itens do nltk, via o comando `nltk.download()`:\n",
    "- Corpus Mac-Morpho\n",
    "- Punkt tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(nltk.corpus.mac_morpho.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('É', 'V'),\n",
       " ('mais', 'ADV'),\n",
       " ('provável', 'ADJ'),\n",
       " ('que', 'KS'),\n",
       " ('essa', 'PROADJ'),\n",
       " ('amostra', 'N'),\n",
       " ('seja', 'V'),\n",
       " ('representativa', 'ADJ'),\n",
       " ('de', 'PREP'),\n",
       " ('toda', 'PROADJ'),\n",
       " ('a', 'ART'),\n",
       " ('população', 'N'),\n",
       " ('feminina', 'ADJ'),\n",
       " ('de', 'PREP|+'),\n",
       " ('a', 'ART'),\n",
       " ('cidade', 'N')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplo de sentença taggeada\n",
    "dataset[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão de conjunto de dados de treino (80%) e teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = len(dataset)\n",
    "tot_train_samples = int(np.ceil(tot*.8))\n",
    "\n",
    "train_data = dataset[:tot_train_samples]\n",
    "test_data = dataset[tot_train_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affix Tagger e Default Tagger\n",
    "\n",
    "Os seguintes classificadores foram construídos de maneira aditiva, começando de um classificador baseline, e montando taggers mais complexos, que se referiam aos taggers criados previamente via a variável `backoff`.\n",
    "\n",
    "O `DefaultTagger` é o tagger baseline, pois ele aplica o mesmo POS para qualquer token. Nesse caso, os tokens são classificados como nomes (N no MacMorpho). Podemos ver que chutando N para o conjunto de teste acerta cerca de 20% dos tokens.\n",
    "\n",
    "Já o `AffixTagger` se baseia em sufixos ou prefixos para a classificação. Podemos passar afixos de diferentes comprimentos, na variável `affix_length`, onde:\n",
    "- Valores positivos se referem a prefixos (Ex: igual, **des**igual)\n",
    "- Valores negativos se referem a sufixos (Ex: japon**ês**, ingl**ês**, portugu**ês**)\n",
    "\n",
    "Como na língua portuguesa o jeito de como a palavra termina pode indicar a classe da palavra (como em verbos, línguas, gerúndio etc), foi utilizado vários taggers de sufixos em cadeia, com cada um aumentando ligeiramente a performance de classificação, chegando a 36.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance dos taggers:\n",
      "         - Default:                     19.68%\n",
      "         - Sufixo tamanho 2 + Default:  27.29%\n",
      "         - Sufixo tamanho 3 + Sufixo 2: 32.23%\n",
      "         - Sufixo tamanho 4 + Sufixo 3: 34.66%\n",
      "         - Sufixo tamanho 5 + Sufixo 4: 36.24%\n",
      "         - Sufixo tamanho 6 + Sufixo 5: 36.71%\n"
     ]
    }
   ],
   "source": [
    "t_def = nltk.DefaultTagger('N')\n",
    "t_affix2 = nltk.AffixTagger(train_data, affix_length=-2, backoff=t_def)\n",
    "t_affix3 = nltk.AffixTagger(train_data, affix_length=-3, backoff=t_affix2)\n",
    "t_affix4 = nltk.AffixTagger(train_data, affix_length=-4, backoff=t_affix3)\n",
    "t_affix5 = nltk.AffixTagger(train_data, affix_length=-5, backoff=t_affix4)\n",
    "t_affix6 = nltk.AffixTagger(train_data, affix_length=-6, backoff=t_affix5)\n",
    "\n",
    "acc_def = t_def.evaluate(test_data) * 100\n",
    "acc_af2 = t_affix2.evaluate(test_data) * 100\n",
    "acc_af3 = t_affix3.evaluate(test_data) * 100\n",
    "acc_af4 = t_affix4.evaluate(test_data) * 100\n",
    "acc_af5 = t_affix5.evaluate(test_data) * 100\n",
    "acc_af6 = t_affix6.evaluate(test_data) * 100\n",
    "\n",
    "print('''Performance dos taggers:\n",
    "         - Default:                     {:.2f}%\n",
    "         - Sufixo tamanho 2 + Default:  {:.2f}%\n",
    "         - Sufixo tamanho 3 + Sufixo 2: {:.2f}%\n",
    "         - Sufixo tamanho 4 + Sufixo 3: {:.2f}%\n",
    "         - Sufixo tamanho 5 + Sufixo 4: {:.2f}%\n",
    "         - Sufixo tamanho 6 + Sufixo 5: {:.2f}%'''.format(acc_def, acc_af2, acc_af3,\n",
    "                                                          acc_af4, acc_af5, acc_af6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram Tagger\n",
    "\n",
    "Um unigrama se refere a um token, um conjunto de uma palavra. Assim o `UnigramTagger` é o tagger que faz a classificação tendo como contexto apenas uma palavra. O tagger gerado tem um grande salto de performance, chegando a 83.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance dos taggers:\n",
      "         - Default:                     19.68%\n",
      "         - Sufixo tamanho 2 + Default:  27.29%\n",
      "         - Sufixo tamanho 3 + Sufixo 2: 32.23%\n",
      "         - Sufixo tamanho 4 + Sufixo 3: 34.66%\n",
      "         - Sufixo tamanho 5 + Sufixo 4: 36.24%\n",
      "         - Sufixo tamanho 6 + Sufixo 5: 36.71%\n",
      "         - Unigrama + Sufixo 6:         83.70%\n"
     ]
    }
   ],
   "source": [
    "t_uni = nltk.UnigramTagger(train_data, backoff=t_affix5)\n",
    "\n",
    "acc_uni = t_uni.evaluate(test_data) * 100\n",
    "\n",
    "print('''Performance dos taggers:\n",
    "         - Default:                     {:.2f}%\n",
    "         - Sufixo tamanho 2 + Default:  {:.2f}%\n",
    "         - Sufixo tamanho 3 + Sufixo 2: {:.2f}%\n",
    "         - Sufixo tamanho 4 + Sufixo 3: {:.2f}%\n",
    "         - Sufixo tamanho 5 + Sufixo 4: {:.2f}%\n",
    "         - Sufixo tamanho 6 + Sufixo 5: {:.2f}%\n",
    "         - Unigrama + Sufixo 6:         {:.2f}%'''.format(acc_def, acc_af2, acc_af3,\n",
    "                                                          acc_af4, acc_af5, acc_af6,\n",
    "                                                          acc_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram e Trigram Tagger\n",
    "\n",
    "O `BigramTagger` e o `TrigramTagger`, utilizam as tags anteriorer como parte do contexto, útil em casos onde um token pode ter diferentes usos dependendo do contexto. Os classificadores tem uma ligeira melhora, om acurácia acima de 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance dos taggers:\n",
      "         - Default:                     19.68%\n",
      "         - Sufixo tamanho 2 + Default:  27.29%\n",
      "         - Sufixo tamanho 3 + Sufixo 2: 32.23%\n",
      "         - Sufixo tamanho 4 + Sufixo 3: 34.66%\n",
      "         - Sufixo tamanho 5 + Sufixo 4: 36.24%\n",
      "         - Sufixo tamanho 6 + Sufixo 5: 36.71%\n",
      "         - Unigrama + Sufixo 6:         83.70%\n",
      "         - Bigrama + Unigrama:          85.18%\n",
      "         - Trigrama + Bigrama:          85.19%\n"
     ]
    }
   ],
   "source": [
    "t_bi = nltk.BigramTagger(train_data, backoff=t_uni)\n",
    "t_tri = nltk.TrigramTagger(train_data, backoff=t_bi)\n",
    "\n",
    "acc_bi = t_bi.evaluate(test_data) * 100\n",
    "acc_tri = t_tri.evaluate(test_data) * 100\n",
    "\n",
    "print('''Performance dos taggers:\n",
    "         - Default:                     {:.2f}%\n",
    "         - Sufixo tamanho 2 + Default:  {:.2f}%\n",
    "         - Sufixo tamanho 3 + Sufixo 2: {:.2f}%\n",
    "         - Sufixo tamanho 4 + Sufixo 3: {:.2f}%\n",
    "         - Sufixo tamanho 5 + Sufixo 4: {:.2f}%\n",
    "         - Sufixo tamanho 6 + Sufixo 5: {:.2f}%\n",
    "         - Unigrama + Sufixo 6:         {:.2f}%\n",
    "         - Bigrama + Unigrama:          {:.2f}%\n",
    "         - Trigrama + Bigrama:          {:.2f}%'''.format(acc_def, acc_af2, acc_af3,\n",
    "                                                          acc_af4, acc_af5, acc_af6,\n",
    "                                                          acc_uni, acc_bi, acc_tri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brill Tagger\n",
    "\n",
    "O `BrillTagger` é um tagger que se baseia na criação de regras para melhorar o desempenho de classificação. Ele é um tagger que demora um pouco para treinar, mas produz um salto na acurácia, chegando a 92.19%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 41118; tokens: 913108; tpls: 37; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 848255 useful rules.\n",
      "Selecting rules...\n",
      "Performance dos taggers:\n",
      "         - Default:                     19.68%\n",
      "         - Sufixo tamanho 2 + Default:  27.29%\n",
      "         - Sufixo tamanho 3 + Sufixo 2: 32.23%\n",
      "         - Sufixo tamanho 4 + Sufixo 3: 34.66%\n",
      "         - Sufixo tamanho 5 + Sufixo 4: 36.24%\n",
      "         - Sufixo tamanho 6 + Sufixo 5: 36.71%\n",
      "         - Unigrama + Sufixo 6:         83.70%\n",
      "         - Bigrama + Unigrama:          85.18%\n",
      "         - Trigrama + Bigrama:          85.19%\n",
      "         - Brill Tagger + Trigrama:     92.19%\n"
     ]
    }
   ],
   "source": [
    "templates = nltk.brill.fntbl37()\n",
    "brill_tagger = nltk.BrillTaggerTrainer(t_tri, templates, trace=True)\n",
    "brill_tagger = brill_tagger.train(train_data)\n",
    "\n",
    "acc_brill = brill_tagger.evaluate(test_data) * 100\n",
    "\n",
    "print('''Performance dos taggers:\n",
    "         - Default:                     {:.2f}%\n",
    "         - Sufixo tamanho 2 + Default:  {:.2f}%\n",
    "         - Sufixo tamanho 3 + Sufixo 2: {:.2f}%\n",
    "         - Sufixo tamanho 4 + Sufixo 3: {:.2f}%\n",
    "         - Sufixo tamanho 5 + Sufixo 4: {:.2f}%\n",
    "         - Sufixo tamanho 6 + Sufixo 5: {:.2f}%\n",
    "         - Unigrama + Sufixo 6:         {:.2f}%\n",
    "         - Bigrama + Unigrama:          {:.2f}%\n",
    "         - Trigrama + Bigrama:          {:.2f}%\n",
    "         - Brill Tagger + Trigrama:     {:.2f}%'''.format(acc_def, acc_af2, acc_af3,\n",
    "                                                          acc_af4, acc_af5, acc_af6,\n",
    "                                                          acc_uni, acc_bi, acc_tri,\n",
    "                                                          acc_brill))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier-based tagging\n",
    "\n",
    "O `ClassifierBasedPOSTagger` é um outro tipo de tagger, desta vez não aditivo como os anteriores, mas sim um modelo baseado em um classificador, como o nome diz. O classificador default do NLTK é uma implementação do algoritmo `Naive-Bayes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance do tagger:\n",
      "         - ClassifierBased (Naive Bayes): 83.97%\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
    "\n",
    "naive_tagger = ClassifierBasedPOSTagger(train=train_data)\n",
    "\n",
    "acc_naive = naive_tagger.evaluate(test_data) * 100\n",
    "\n",
    "print('''Performance do tagger:\n",
    "         - ClassifierBased (Naive Bayes): {:.2f}%'''.format(acc_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando os taggers\n",
    "\n",
    "Com os taggers treinados, podemos salvar eles em arquivos `pickle` para uso posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_POS_taggers/POS_tagger_naive.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = 'trained_POS_taggers/'\n",
    "joblib.dump(t_affix6,folder+'POS_tagger_affix6.pkl')\n",
    "joblib.dump(t_uni,folder+'POS_tagger_unigram.pkl')\n",
    "joblib.dump(t_bi,folder+'POS_tagger_bigram.pkl')\n",
    "joblib.dump(t_tri,folder+'POS_tagger_trigram.pkl')\n",
    "joblib.dump(brill_tagger,folder+'POS_tagger_brill.pkl')\n",
    "joblib.dump(naive_tagger,folder+'POS_tagger_naive.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando arquivo pkl para uso dos POS-taggers treinados\n",
    "\n",
    "Para utilizar eles, basta carregar o arquivo `pickle` gerado, como por exemplo, usando a função `load` da biblioteca `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'ART'),\n",
       " ('rato', 'N'),\n",
       " ('roeu', 'V'),\n",
       " ('a', 'ART'),\n",
       " ('roupa', 'N'),\n",
       " ('do', 'KS'),\n",
       " ('rei', 'N'),\n",
       " ('de', 'PREP'),\n",
       " ('Roma', 'NPROP')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_tagger = joblib.load(folder+'POS_tagger_brill.pkl')\n",
    "\n",
    "phrase = 'O rato roeu a roupa do rei de Roma'\n",
    "\n",
    "teste_tagger.tag(word_tokenize(phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação dos taggers - Tempo \n",
    "\n",
    "Para uma comparação do desempenho dos taggers treinados, vamos medir o tempo gasto para classificar as primeiras 100 sentenças do Mac-Morpho, que tem ao todo 2260 palavras. Para efeitos de comparação, esse teste foi feito em Python 3.6, em uma máquina com processador Intel i7 e 16 GB de RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palavras nas 100 primeiras sentenças do Mac-Morpho: 2260\n"
     ]
    }
   ],
   "source": [
    "sent_test = nltk.corpus.mac_morpho.sents()[:100]\n",
    "tot_words = sum([len(s) for s in list(sent_test)])\n",
    "\n",
    "print('Total de palavras nas 100 primeiras sentenças do Mac-Morpho: {}'.format(tot_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.2 ms ± 1.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t_affix6.tag_sents(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.5 ms ± 831 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t_uni.tag_sents(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.6 ms ± 4.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t_bi.tag_sents(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.6 ms ± 2.81 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t_tri.tag_sents(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.9 ms ± 8.52 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit brill_tagger.tag_sents(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.87 s ± 36.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit naive_tagger.tag_sents(sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras processadas por segundo (palavras/s):\n",
      "         - Sufixo tamanho 6 + Sufixo 5:   72435.90 palavras/s\n",
      "         - Unigrama + Sufixo 6:           82181.82 palavras/s\n",
      "         - Bigrama + Unigrama:            67261.90 palavras/s\n",
      "         - Trigrama + Bigrama:            61748.63 palavras/s\n",
      "         - Brill Tagger + Trigrama:       30173.56 palavras/s\n",
      "         - ClassifierBased (Naive Bayes):   787.46 palavras/s\n"
     ]
    }
   ],
   "source": [
    "words_sec_affix6 = 1/((31.2* 10**-3)/tot_words)\n",
    "words_sec_uni = 1/((27.5* 10**-3)/tot_words)\n",
    "words_sec_bi = 1/((33.6* 10**-3)/tot_words)\n",
    "words_sec_tri = 1/((36.6* 10**-3)/tot_words)\n",
    "words_sec_brill = 1/((74.9* 10**-3)/tot_words)\n",
    "words_sec_naive = 1/(2.87/tot_words)\n",
    "\n",
    "print('''Palavras processadas por segundo (palavras/s):\n",
    "         - Sufixo tamanho 6 + Sufixo 5:   {:.2f} palavras/s\n",
    "         - Unigrama + Sufixo 6:           {:.2f} palavras/s\n",
    "         - Bigrama + Unigrama:            {:.2f} palavras/s\n",
    "         - Trigrama + Bigrama:            {:.2f} palavras/s\n",
    "         - Brill Tagger + Trigrama:       {:.2f} palavras/s\n",
    "         - ClassifierBased (Naive Bayes):   {:.2f} palavras/s'''.format(words_sec_affix6, words_sec_uni,\n",
    "                                                                        words_sec_bi, words_sec_tri,\n",
    "                                                                        words_sec_brill, words_sec_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "Podemos montar uma tabela final com os dados dos modelos treinados. Podemos ver que o BrillTagger teve a melhor acurácia, sendo um pouco mais lento que os modelos feitos antes dele. E o modelo baseado no Naive-Bayes além de não ter a melhor acurácia, produziu o maior pickle, e foi de longe o mais lento, não indicado para uso para corpus grandes:\n",
    "\n",
    "\n",
    "| Tagger                 | Acurácia | Palavras/s | Tamanho  |\n",
    "|------------------------|----------|------------|----------|\n",
    "| POS_tagger_affix6.pkl  | 36.71%   | 72k        | 386 kB   |\n",
    "| POS_tagger_unigram.pkl | 83.70%   | **82k**        | 790 kB   |\n",
    "| POS_tagger_bigram.pkl  | 85.18%   | 67k        | 1.37 MB  |\n",
    "| POS_tagger_trigram.pkl | 85.19%   | 61k        | 2.05 MB  |\n",
    "| POS_tagger_brill.pkl   | **92.19%**   | 30k        | 2.09 MB  |\n",
    "| POS_tagger_naive.pkl   | 83.97%   | 787        | 22.43 MB |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face-env]",
   "language": "python",
   "name": "conda-env-face-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
